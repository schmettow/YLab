---
title: "CORY_0: Visualizing multi-sensor data streams"
author: "Martin Schmettow & Karel Kroeze"
format: html
editor: visual
---

```{r include=FALSE}
setwd(here::here("apps/ylab_2/"))
library(tidyverse)
library(readr)
```

## Results

### Creating a helper function

We define a helper function to read data files generated by Ylab, and do a bit of pre-processing.

```{r}
#' Read Ylab data files
#' 
#' Reads a data file created by Ylab, and does some cleanup and 
#' preprocessing.
#' 
#' @param {path} path to the data file
#' @param {col_types} list of named column definitions. The list is 
#'  passed to the `col_types` argument of `readr::read_csv(...)`, 
#'  while the names are passed to the `col_names` argument.
#' @return {tibble} a tibble with four columns: `Source`, `time`, 
#'  `Sensor` and `value`. 
read_ydata <-
  function(path,
           # data files have three columns: 
           #  - time (in seconds) since the device was powered
           #  - Sensor ID/name (defined in the script)
           #  - value of the measurement
           #  
           # We could let R decide how to load the data, and it
           # would probably do a good job guessing the data types,
           # but it's good practice to explicitly define what we 
           # expect. 
           col_types = list(time = col_double(),
                            Sensor = col_character(),
                            value = col_double())) {
    
    # read the data, using the column names and data types defined
    #  in the function definition.
    read_csv(path,
             col_names = names(col_types),
             col_types = col_types) %>%
      
      # add a column identifying which file each measurement was
      # read from, and 'cast' the time into a form that tidy 
      # functions will correctly recognize and treat as a time 
      # format.
      # 
      # Note that the device only knows the time since it was
      # powered on - and not the 'actual' time. If we create multiple
      # datasets and turn the device off and on between datasets, 
      # the time will reset. We may have to manually add an 'origin'
      # or a baseline time to avoid measurements from different 
      # sources overlapping on the timeline.
      mutate(Source = path,
             time = lubridate::as_datetime(time)) %>%
      
      # return only the columns we explicitly defined, dropping 
      # any extra columns that may have been present in the data
      select(Source, time, Sensor, value) %>%
      
      # arrange measurements by time and sensor, if they weren't
      # already.
      arrange(time, Sensor)
    
    # R returns the result of the last expression in a function
    # if there is no explicit `return()` statement. In this case,
    # that means the result of the read - mutate - select - arrange
    # pipeline.
    
  }
```

### Batch reading the data

As Data Scientists, we don't want to have to manually write a script to load each data file. Let's instead write some code to load all data files in a directory - no matter how many there are.

```{r}
# We use the 'dir(...)' function to get a list of 
# files in a given location. In this case, the 'data'
# folder next to this script.
files <- dir("data/", full.names = T)

# I only have one file on this test
files

```

```{r}
# assuming we have anywhere from one to many files:
D_1 <-
  # take our list of filepaths...
  files %>%
  
  # And 'map' them onto the `read_ydata` function, 
  # combining the results in a single 'data frame'.
  # 
  # Note that 'df' here is historical, the function
  # actually returns a 'tibble'. Both formats are 
  # different implementations of tabular data, and 
  # the difference is _usually_ not important. 
  map_df(read_ydata) %>%
  
  # The data from each file is put in order of the 
  # files, so lets make sure they are in a predic-
  # table order again.
  arrange(Source, time, Sensor) %>% 
  mutate(Sensor = str_replace(Sensor, "Yema_ads0", "ECG"),
         Sensor = str_replace(Sensor, "Yeda0", "EDA"))

# we now have a single data frame containing all the
# measurements of each of the data files in the 'data'
# folder.

D_1
```

### Summarizing observations

Before we move on, let's have a quick look at what kind of data we have.

```{r}
# let's see how many measurements we have for each 
# sensor (or moment of interest).
D_1 %>%
  
  # group measurements by source and sensor name
  group_by(Source, Sensor) %>%
  
  # summarize each group by counting the number of
  # measurements
  summarize(n = n())

# note that because this is a very common operation,
# tidyr includes a shorthand function for it:
D_1 %>% count(Source, Sensor)
```

### Plotting a timeline

Let's start with a naive plot, putting time on the x axis, sensor values on the y axis, using a line to track values over time, and distinguishing different sensors with different colours.

```{r}
D_1 %>% 
  ggplot(aes(x = time, y = value, colour = Sensor)) + 
  geom_line()

```

That works, but it's not very elegant. Our first problem is the different ranges of different sensors. We could work with dual scales, but this is generally considered a [bad ideaâ„¢](https://blog.D_1wrapper.de/dualaxis/) (and in fact, [is deliberately very difficult to do in ggplot](https://stackoverflow.com/questions/3099219/ggplot-with-2-y-axes-on-each-side-and-different-scales/3101876#3101876)). A simple and effective alternative is to use facets instead.

```{r}
D_1 %>% 
  ggplot(aes(x = time, y = value)) + 
  facet_grid(
    # create a tabular grid showing sources in the columns (we
    # have only one here), and sensors in the rows. 
    # 
    # We use 'free_y' in the `scales` argument to allow ggplot
    # to pick an appropriate scale for the y axes on each plot. 
    # If we didn't leave the y axis 'free', we'd have the same 
    # scale problem as on the first plot. 
    Sensor~Source, scales = "free_y") + 
  geom_line()
```

That's better, but the moments of interest aren't actually continuous D_1 streams, and visualizing them as such makes little sense. Let's remove them, and visualize them as markers identifying specific points in time instead.

```{r}
# first, remove the moments of interest from our plot
G_0 <- D_1 %>%
  # match any rows where the sensor name _does not_ start with "MOI"
  filter(Sensor %>% str_starts("MOI", negate = TRUE)) %>%
  ggplot(aes(x = time, y = value)) +
  facet_grid(Sensor ~ Source, scales = "free_y") +
  geom_line()

G_0
```

```{r}

# then, add a new layer that _only_ uses the moment of interest
# data.
D_2 <- D_1 %>% filter(Sensor %>% str_starts("MOI"))

G_0 +
  geom_vline(
    aes(xintercept = time, colour = Sensor), 
    data = D_2
  )
```

Okay.... that's.... better? It's still not what we wanted, though. It looks like we'll need to further massage the data. As moments of interest and sensor measurements are interpreted in different ways, we should probably distinguish between them. The fastest way to do that is to simply rename the column.

```{r}
D_3 <- D_2 %>% 
  rename(moi = Sensor)

G_0 + 
  geom_vline(
    aes(xintercept = time, colour = moi), 
    data = D_3
  )
```

Better! We can now easily see overall patterns in both sensors, and relate them to specific moments of interest.

### Deriving phases from events

So far, we've been visualizing raw sensor data. One might wonder if this actually makes sense. Have you noticed that the ECG signal shows a long-term rhythm that is congruent with the MOIs? Well, during this experiment, the participant pressed Moi0, when the starting to breath in, and Moi1, when breathing out. We can clearly see how the ECG amplitude rises when breathing in and falls when breathing out.

An ECG sensor that also works as a respiration sensor? Let's examine this , well, breath-taking possibility further. In the raw data set, MOIs are coded as mere events, while for the following analysis, it is more suited to have some sort of *episode* coding, such that every other measure "knows" to which breath it belongs and to which phase of the breath. That seems to require some more complex tidyverse trickery.

Data set D_2 is a selection with only the MOI events. That is a good point to start.

```{r}
D_4 <-
  D_2 %>% 
  mutate(Phase = if_else(Sensor == "MOI0", "In", "Out")) %>% 
  group_by(Source, Sensor) %>% 
  mutate(time = time,
         breath = row_number()) %>% 
  select(-value) %>% 
  ungroup()
```

Now, we use a Join operation, to merge D_4 with D_1. By using a left join, D_1 is kept entirely, and information from D_4 is added as new variables. Join operations operate on identifier variables, also called the *key*. The key of a table is the minimum set of variables that uniquely identifies every observation. Here that is source, time and sensor. Note that we had excluded value from D_4, as only key variables should be (and must be) present in both tables. The result is a table, where the MOIs are classified by breath number and phase. Both classifiers are blank (NA) for all other sensors. By the downwards fill operation (see [here](https://www.digitalocean.com/community/tutorials/fill-missing-values-in-tidyr-r)) the remaining measures are classified by whatever MOI happened last. Finally, all unclassified measures (before the first MOI marker) are removed. Finally, we create a new time indicator, that is reset with every breath.

```{r}
D_5 <- 
  D_1 %>% 
  left_join(D_4, by = c("Source", "time", "Sensor")) %>% 
  fill(breath, .direction = "down") %>% 
  fill(Phase, .direction = "down") %>% 
  filter(!is.na(breath)) %>%
  group_by(Source, breath) %>% 
  mutate(breath_time = time - min(time, na.rm = T)) %>% 
  arrange(Source, time) %>% 
  print()
  
```

Now we can use the extra variables episode and Phase to create some specialized plots, with the purpose of reviewing the influence of breath on ECG amplitude.

```{r}
D_5 %>% 
  filter(Sensor == "ECG") %>% 
  ggplot(aes(x = breath_time, y = value, color = Phase)) +
  geom_line(aes(group = 1)) +
  facet_grid(breath ~ Source, scales = "free_y")
```

### Using derivatives

In the above plot, we can clearly see the periodic shape of the heartbeat. The question is, how do we identify the individual beats. A naive approach would be to try to set a threshold value to collect the peak moments, but that has two disadvantages. First, the amplitude varies a lot. If you select a too high value, you will be missing the low beats. If you set the threshold lower, the high peaks are getting a "big foot", introducing uncertainty of when the beat happened precisely.

Another way is to use derivatives. Rather than using absolute values, we are looking at the slope $\beta$ of the signal, which we can simply compute as the difference in values $y$ divided by the difference in time:

$$
\beta_i = (y_i - y_{i-1})/(t_i - t_{i-1}) 
$$

```{r}
deriv <- function(value, time)
  return((value - lag(value))/(as.numeric(time) - lag(as.numeric(time))))


D_6 <-
  D_5 %>% 
  filter(Sensor == "ECG", breath == 1, Phase == "In") %>% 
  group_by(Source, Sensor) %>% 
  mutate(value_d1 = deriv(value, time),
         value_d2 = deriv(value_d1, time),
         value_d3 = deriv(value_d2, time)) %>% 
  ungroup()
  

head(D_6)
  
```

```{r fig.height = 12, fig.width = 6}
D_6 %>% 
  select(Source, breath_time, starts_with("value")) %>% 
  pivot_longer(cols = starts_with("value"), names_to = "Function") %>% 
  ggplot(aes(x = breath_time, y = value)) +
  geom_line(aes(group = 1)) +
  facet_grid(Function ~ Source, scales = "free_y")
```

```{r}
mean_base = mean(D_6$value, na.rm = T)
scale_1 = 20
scale_2 = 2000


G_1 <- 
  D_6 %>% 
#  filter(breath_time < 2) %>% 
  mutate(value = value - mean_base,
         value_d1 = value_d1/scale_1,
         value_d2 = value_d2/scale_2) %>% 
  ggplot(aes(x = breath_time, y = value)) +
  geom_line(aes(group = 1, color = "base")) +
  geom_line(aes(group = 1, y = value_d1, color = "deriv_1")) +
  geom_line(aes(group = 1, y = value_d2, color = "deriv_2")) +
  facet_grid(1 ~ Source, scales = "free_y")

G_1
```

```{r}
thresh_0 = 0.005 + mean_base
thresh_1 = 0.05 * scale_1
thresh_2 = -0.005 * scale_2
thresh_time = 0.3 # max of ~200 bpm

D_7 <- 
  D_6 %>% 
  mutate(crit_0 = value > thresh_0,
         crit_1 = abs(value_d1) < thresh_1,
         crit_2 = value_d2 < thresh_2) %>% 
  filter(crit_0, crit_1, crit_2) %>% 
  mutate(d_time = breath_time - lag(breath_time),
         start_beat = d_time > thresh_time) %>% 
  filter(start_beat)
  

G_1 +
  geom_point(aes(x = breath_time,
                 y = 0), 
             data = D_7, size = 4)
  
```
